# 最適化結果の実務判断と次のアクション

**作成日**: 2025-12-31  
**参照データ**: 
- `OPTIMIZATION_RESULT_REPORT_20251231.md`
- `top_10_trials_optimization_timeseries_20251231_081028.json`
- 最適化実行: 2025-12-31 08:10:28（100 trials、期間: 2020-01-01 ～ 2024-12-31）

---

## 1. 現状評価（いま何が言えるか）

### 1.1 最良値の評価（best=0.3310、median=-0.0095）

#### **best Sharpe_excess=0.3310（年率化）の解釈**

**結論**: 「候補としては十分に魅力がある」が、確証としては弱い

**理由**:
- **観測点数が少ない**: 月次60点（60リバランス）のみ
- **Sharpe推定誤差が大きい**: 60点のSharpeは"ブレ"が大きく、0.33程度はノイズで出てもおかしくないレンジ
- **多重比較バイアス**: 100回最適化して「一番良いもの」を拾っているため、偶然の上位値が選ばれている可能性

**実務的評価**:
- ✅ **候補としての価値は十分**: 0.33の超過Sharpeは実用的
- ⚠️ **この値だけでGO判断は危険**: OOS（Holdout/WFA）での再現性確認が必須

#### **median=-0.0095（ほぼゼロ）の解釈**

**結論**: 「ランダムにパラメータを引くと、超過Sharpeはだいたいゼロ近辺」= 戦略自体のベース優位性は大きくなく、パラメータで当たり外れが出る

**前回比較**:
- 前回（50 trial）: median = -0.1455
- 今回（100 trial）: median = -0.0095
- **改善**: "探索空間が広すぎて負けパラメータを大量に引いていた状態"から、"探索空間がだいぶ現実的な領域に寄ってきた"ことを示唆

**実務的評価**:
- ✅ **探索空間の改善は確認できた**: median改善は良いサイン
- ⚠️ **ベース優位性は小さい**: パラメータ選択が重要（過学習リスクに注意）

---

### 1.2 パラメータ重要度の解釈（bb_weightが最重要）

#### **bb_weight相関0.7418（最重要）の意味**

**実務的含意**:
1. **エントリー（タイミング）側の設計が勝敗を決めている**
   - core（quality/value/growth/…）は銘柄選別
   - entry scoreは売買タイミング
   - BB（ボリンジャー）寄りに重みを寄せるほどSharpeが上がる

2. **「閾値より配分（構造）」が効いている**
   - `bb_z_base` / `bb_z_max` がほぼ無相関（-0.0333 / 0.0333）
   - `bb_weight` が効く
   - → 閾値の最適点が鋭いのではなく、**構造的にBBを重くするほど良い（単調性）**可能性

3. **bestが上限側（0.6832）に張り付いている**
   - 現在の範囲: 0.45 ～ 0.75
   - best値: 0.6832（上限に近い）
   - → **次回は上限を広げて"まだ伸びるのか/頭打ちか"を見る価値が高い**

**注意点**:
- 単純相関は「非線形」「交互作用」を取り逃がす
- 次回はOptunaのfANOVA重要度やSHAP的な重要度も併用したい（できれば全trialデータで）

---

### 1.3 上位10 trialの分布から見える傾向

#### **頑健性の兆し**

- **Sharpe_excess分布**: 平均0.2462、中央値0.2367、最小0.1792
- **評価**: 上位解がそこそこ固まっている → 「偶然の一発」よりは良いサイン

#### **境界張り付き（懸念点）**

best（Trial #1）がいくつかのパラメータで**「上位10内の端（境界）」**にいる:

| パラメータ | best値 | 上位10内での位置 |
|-----------|--------|----------------|
| `bb_weight` | 0.6832 | **最大**（上限に近い） |
| `w_forward_per` | 0.5387 | **最大** |
| `roe_min` | 0.0591 | **最小**（下限に近い） |
| `rsi_max` | 78.83 | **最大** |

**2通りの解釈**:
- **(A) まだ探索範囲が狭く、真の最適はもっと外側** → 範囲を広げるべき
- **(B) in-sampleノイズで端が選ばれただけ** → 過学習の兆候

**判定方法**: Holdout/WFAでの再現性か、**best近傍の局所感度分析（少しずつ動かす）**が必要

#### **上位10 trialの2クラスタ構造**

上位10は概ね以下の2つの"流派"が見える:

| クラスタ | 特徴 | 代表trial | average objective |
|---------|------|-----------|------------------|
| **A（BB重視・ROE閾値低め・w_value低め）** | bb_weight平均≈0.567<br>roe_min平均≈0.067<br>w_value平均≈0.298 | Trial #1（best, 0.3310） | ≈0.285 |
| **B（w_value高め・ROE閾値やや高め・BBは中程度）** | bb_weight平均≈0.484<br>roe_min平均≈0.107<br>w_value平均≈0.381 | Trial #63（2位, 0.3204） | やや下がる |

**示唆**: 「良さそうな領域が1つではなく複数ある」可能性があるため、次回は1本の探索空間で無理に混ぜるより、**領域を分けて最適化したほうが効率が良い**

---

### 1.4 前回（50 trial）との比較から見える改善点

| 項目 | 前回（50 trial） | 今回（100 trial） | 変化 |
|------|----------------|------------------|------|
| **best Sharpe_excess** | 0.3310 | 0.3310 | 同値 |
| **median Sharpe_excess** | -0.1455 | -0.0095 | **大幅改善** ✅ |
| **平均data_fetch_time** | 2,257.58s | 681.02s | **-70%** ✅ |
| **合計実行時間** | 31.4時間 | 19.0時間 | **-39%** ✅ |
| **p95 Sharpe_excess** | 0.2724 (82.3%) | 0.2286 (69.1%) | -16.1% |

**評価**:
- ✅ **探索空間の改善**: median大幅改善は最適化の"土台"が良くなった強い証拠
- ✅ **実行時間の改善**: 70%改善は素晴らしい（ただし、まだ99.9%がdata_fetch_time）
- ⚠️ **p95の低下**: 50→100で統計の不安定さもあるし、探索範囲/サンプラー挙動でも動くので、"悪化"と断定しないのが安全

---

## 2. 次のステップ（何をやるべきか）

### 2.1 最優先: data_fetch_timeの構造改善（681秒/trial → 目標30〜60秒/trial）

**現状**: 99.9%がdata_fetch_timeで、ここがボトルネック

**原因の可能性（効果が大きい順）**:

1. **"キャッシュのキー"がtrialごとに変わっていて、実質ヒットしていない**
   - 例: fetch関数がparamsを引数に持っていて、毎回別キー扱いになる
   - **対策**: 「市場データ・ファンダ・テクニカル指標」の生成はparams非依存に切り出す。objective内は「既にある特徴量に重み付け＆閾値処理だけ」にする

2. **毎trial、巨大データを読み直している（I/Oが支配）**
   - **対策（実務で効く順）**:
     1. 1回の最適化実行の冒頭で全データをロードし、プロセス内で使い回す（closure / global）
     2. 保存形式をParquet（pyarrow）等にして列指向で必要列だけ読む
     3. "月次60点×銘柄数"の特徴量を、リバランス日単位で辞書化して持つ（dict[rebalance_date] -> DataFrame）

3. **並列化時に巨大オブジェクトの受け渡し（pickle）が発生している**
   - **対策**:
     - ワーカー初期化でデータロード（initializer）→ trialごとに渡さない
     - 共有メモリ/メモリマップの活用（numpy memmap等）
     - Optunaのn_jobs設計を見直す（スレッド/プロセス）

4. **"本当は特徴量計算が重い"のにdata_fetch_timeにまとめて計測している**
   - **対策**: 計測区間を分解して、`load_time`、`feature_calc_time`、`cache_read_time`、`universe_filter_time`を別々に出す

**目標ライン（現実的）**:
- まずは: **681秒 → 30〜60秒/trial**（データ読み直し排除）
- 次に: **数秒〜10秒台/trial**（特徴量を完全事前計算し、trialは線形結合だけ）

**重要性**: 200〜300 trialを回すなら、ここが改善できるかどうかで「回せる最適化の質」が別物になる

---

### 2.2 次回最適化（200-300 trial）のパラメータ範囲提案

#### **方針**: クラスタ分割＋次元削減

**理由**:
- 上位10に"2流派"が見えるため、1本の探索空間で無理に混ぜるとTPEが迷子になる
- 重要度が低いパラメータは固定/狭小化して過学習リスクも計算時間も下げる

#### **推奨: 固定または狭くする候補**

上位10で安定し、相関も弱いものは、まず固定/狭小化して良い:

| パラメータ | 現行範囲 | 推奨範囲 | 理由 |
|-----------|---------|---------|------|
| `w_record_high` | 0.03～0.15 | **0.035～0.065（または固定0.045）** | 上位10で非常に安定（0.0316～0.0613） |
| `rsi_max` | 70.0～85.0 | **76.5～79.0** | 上位10で安定（76.56～78.83） |
| `liquidity_quantile_cut` | 0.15～0.35 | **0.16～0.25** | 上位10で比較的安定（0.1629～0.2500） |

#### **推奨: 広げるべき（境界張り付き＆重要）**

| パラメータ | 現行範囲 | 推奨範囲 | 理由 |
|-----------|---------|---------|------|
| `bb_weight` | 0.45～0.75 | **0.45～0.85（or 0.90）** | 最重要パラメータ、bestが上限側（0.6832）に張り付き |
| `roe_min` | 0.05～0.12 | **0.00～0.12** | 低いほど良い傾向、bestが最小値（0.0591）に張り付き |
| `w_forward_per` | 0.35～0.65 | **0.30～0.75** | 高い方が良い傾向、bestが上限側（0.5387）に張り付き |

#### **推奨: 不安定パラメータは「上位10レンジ＋少しだけ余白」**

| パラメータ | 現行範囲 | 推奨範囲 | 理由 |
|-----------|---------|---------|------|
| `rsi_base` | 35.0～60.0 | **40.0～58.0** | 上位10が約37.85～55.92 |
| `bb_z_base` | -2.0～0.0 | **-2.0～-0.8** | 上位10が約-1.8880～-0.9032 |
| `bb_z_max` | 2.0～3.5 | **2.0～3.6** | 上位10が約2.0531～3.4746 |

#### **推奨: クラスタ分割した探索空間（Study A/B）**

**Study A（BB寄り・低ROE閾値）**: best系を深掘り

```python
{
    "bb_weight": (0.55, 0.90),        # 広げる
    "roe_min": (0.00, 0.08),          # 広げる（下限を外す）
    "w_value": (0.20, 0.35),          # 狭める（上位10のAクラスタ範囲）
    "w_forward_per": (0.40, 0.80),    # 広げる
    "w_record_high": (0.035, 0.065),  # 狭める
    "rsi_max": (76.5, 79.0),          # 狭める
    "liquidity_quantile_cut": (0.16, 0.25),  # 狭める
    "rsi_base": (40.0, 58.0),         # 狭める
    "bb_z_base": (-2.0, -0.8),        # 狭める
    "bb_z_max": (2.0, 3.6),           # 少し広げる
    # その他は現行のまま
}
```

**Study B（Value寄り・ROE閾値やや高め）**: Trial #63系を深掘り

```python
{
    "bb_weight": (0.40, 0.65),        # 狭める（上位10のBクラスタ範囲）
    "roe_min": (0.08, 0.15),          # 狭める（上位10のBクラスタ範囲）
    "w_value": (0.33, 0.50),          # 狭める（上位10のBクラスタ範囲）
    "w_forward_per": (0.30, 0.55),    # 狭める
    "w_record_high": (0.035, 0.065),  # 狭める（共通）
    "rsi_max": (76.5, 79.0),          # 狭める（共通）
    "liquidity_quantile_cut": (0.16, 0.25),  # 狭める（共通）
    "rsi_base": (40.0, 58.0),         # 狭める（共通）
    "bb_z_base": (-2.0, -0.8),        # 狭める（共通）
    "bb_z_max": (2.0, 3.6),           # 少し広げる（共通）
    # その他は現行のまま
}
```

**効果**: 「異なる局所解が混ざってTPEが迷う」問題が軽くなり、200〜300 trialでも収束が見えやすい

---

### 2.3 Holdout検証の実施方法と評価基準（実務で使える形）

#### **重要ポイント**: 今回の最適化は2020-2024全期間を使っている

この結果のパラメータをそのまま2024で測っても、厳密には"Holdout"ではない（すでに見ている期間を使っているため）

#### **推奨Holdout設計（現実的で統計もマシ）**

- **Train期間**: 2020-01～2022-12（36ヶ月）
- **Test期間**: 2023-01～2024-12（24ヶ月）
- **理由**: 月次24点あると、12点よりは評価が安定する

#### **手順（おすすめ運用）**

1. **Train期間だけでOptunaを回す**（200 trial目標。速度がネックなら100でも可）
2. **Trainでの上位K（例：10〜20）を固定**
3. **Testで一切チューニングせずに評価**
4. **さらにTest内で年別（2023/2024）に分解して安定性確認**

#### **評価基準（最低限）**

| 指標 | 合格ライン | 優秀ライン | 説明 |
|------|-----------|-----------|------|
| **Test Sharpe_excess** | > 0.10 | > 0.20 | 最低ライン、0.20ならかなり良い |
| **Test MaxDD** | 許容レンジ内 | 小さいほど良い | 運用要件次第 |
| **月次勝率（excessがプラスの月割合）** | > 55% | > 60% | 目安、安定性の指標 |
| **年別安定性** | 両年プラス | 両年>0.10 | 片年だけで稼いでいないことを確認 |

**重要な判断基準**:
- Sharpeだけでなく、**「崩れ方」**が重要
- 0.1未満でも、DDが小さく安定なら"組み合わせの部品"として価値がある場合がある

---

### 2.4 WFA（Walk-Forward Analysis）の実施方法

Holdoutで感触が良ければWFAへ。

#### **推奨WFA（expanding window / 年次更新）**

| Fold | Train期間 | Test期間 | 説明 |
|------|----------|---------|------|
| Fold1 | 2020-2021 | 2022 | 最初の2年で学習 |
| Fold2 | 2020-2022 | 2023 | 最初の3年で学習 |
| Fold3 | 2020-2023 | 2024 | 最初の4年で学習 |

**手順**:
- 各foldで「Train内最適化 → そのパラメータをTestに適用」を行う
- Test Sharpe_excessの平均・分散、「最低fold」が致命的に悪くないかを確認

#### **合格のイメージ**

- **3fold中、2fold以上がプラス**、かつ**平均が>0.1**
- **1foldがマイナスでも「下げが浅い（例：-0.05程度）」なら許容**
- **1foldで大きく崩れる（例：-0.3）なら、相場レジーム依存が強い可能性**

---

## 3. 実務的な判断（いま進むべき道）

### 3.1 いまHoldoutへ進むべきか？再最適化が先か？

**結論**: **Holdout（ただし"Trainだけで再最適化した上で"）に進むのを推奨**

**理由**:
- bestが0.331でも、60点Sharpeは誤差が大きく、in-sampleだけ深掘りすると過学習が進むリスクが高い
- 一方で、上位10がまとまっているので「候補がない状態」ではない
- → **"OOSで残るか"を早めに確認した方が、次の投資（200–300 trial）を正当化できる**

**ただし現実問題として、data_fetch_timeが重いので**:

1. **data_fetch_timeの構造改善**（設計変更）
2. **Train期間での再最適化**（200前後）
3. **Test評価**

の順が最も筋が良い。

---

### 3.2 Trial #1（最良パラメータ）の頑健性見解

**良い点**:
- 上位10平均が0.246でまとまり、bestだけが突出している感じではない
- bb_weight高め・roe_min低めなど、"方向性"として一貫したシグナルがある

**懸念点**:
- bestが複数パラメータで"端"（上位10内最大/最小）→ 範囲依存かノイズか未確定
- Trial #1が"初期探索で発見"されている → 偶然当たりの可能性も残る

**実務推奨**:
- 「Trial #1を唯一解として採用」ではなく、**上位5〜10を"候補群"としてHoldoutへ**が堅い

---

### 3.3 過学習リスク評価

**結論**: 過学習リスクは**"中〜高"**

**理由**:
1. **パラメータ13個に対し、評価点は月次60点**: 自由度が高い
2. **100 trialのbest-of選抜**: 多重比較バイアスが強い
3. **medianがほぼゼロ**: 「当たりを引くゲーム」要素が残る

**過学習を抑える現実的な手**:
1. **重要度が低いものを固定して次元削減**（特にentry閾値の一部）
2. **目的関数をSharpe単独から、Sharpe − λ * turnover / Sharpe − λ * MaxDD のように"罰則付き"にする**（運用目的に合う）
3. **Holdout/WFAを必須ゲートにする**

---

## 4. その他の気づき・改善提案（重要そうな順）

### 4.1 ユニバース定義の注意（東証プライムは2022年開始）

**問題**: 2020〜2021を含むので、「当時の構成銘柄」をどう扱っているかでバイアスが出る

**リスク**: もし"現在のプライム採用銘柄"を過去に遡って使っていると、**サバイバーシップ・バイアス**が強烈に乗る

**影響**: Sharpe 0.33を簡単に"見かけ上"作ってしまう典型なので、**念のため最優先で確認推奨**

---

### 4.2 今回の知見は「bb_weight（構造）」に寄っている

**観察**:
- 閾値系（rsi_base, bb_z_base/max）が不安定で相関も弱い
- bb_weight（配分）が最重要

**示唆**:
- "閾値を最適化する設計"より、**"シグナル合成（bb_weight）やcore側の作り込み"**のほうが再現性が出る可能性がある

---

### 4.3 結果保存を工夫するとHoldout/WFAが超軽量化できる

**提案**:
- 各trialで「月次（リバランス間）超過リターン列」を保存しておく
- → 同じtrial結果から任意の期間Sharpeを切り出せる
- → Holdout/WFAの再計算が不要になる

**効果**: data_fetch_time地獄の状況では特に効く

---

## 5. 最終提案（迷わないための"次にやること"チェックリスト）

### 即座に実施（最優先）

- [ ] **data_fetch_timeの中身を分解計測**（cache hitしているか確認）
- [ ] **params非依存のデータ生成をobjective外へ追い出す**（特徴量事前計算・使い回し）

### 短期（1-2週間）

- [ ] **Train(2020-2022)で再最適化**（study A/Bに分割、合計200–300 trial）
- [ ] **Test(2023-2024)で固定評価**（Sharpe/MaxDD/勝率/年別安定性）

### 中期（1ヶ月）

- [ ] **WFA（3fold）**を実施
- [ ] **過学習評価**（best近傍の局所感度分析）

### 必要なら実施

- [ ] **ユニバース定義の確認**（サバイバーシップ・バイアスの有無）
- [ ] **OptunaのfANOVA重要度やSHAP的重要度の併用**（全trialデータで）
- [ ] **目的関数の罰則項追加**（turnover/MaxDDペナルティ）

---

## 付録: 次回実装時の参考

### Study A/BそれぞれのOptunaサンプラー設定

**推奨**: TPE multivariate（Optunaデフォルト）を維持

**理由**: クラスタ分割しているので、各study内ではmultivariateで問題ない

**代替案**: CMA-ESも試す価値はあるが、まずはTPEで確認

---

### 次元削減の具体案（固定候補）

```python
# 固定する候補（上位10で非常に安定）
FIXED_PARAMS = {
    "w_record_high": 0.045,  # 上位10平均: 0.0422
    "rsi_max": 77.6,         # 上位10平均: 77.61
    "liquidity_quantile_cut": 0.20,  # 上位10平均: 0.2034
}
```

---

### Holdout/WFAの評価指標テンプレ（集計表フォーマット）

```python
# 評価結果の集計テンプレート
EVALUATION_TEMPLATE = {
    "train_period": "2020-01-01 ~ 2022-12-31",
    "test_period": "2023-01-01 ~ 2024-12-31",
    "top_k_trials": 10,  # 評価対象のtrial数
    "metrics": {
        "sharpe_excess": {
            "train": [],  # 各trialのtrain Sharpe
            "test": [],   # 各trialのtest Sharpe
            "test_2023": [],  # 各trialのtest 2023年Sharpe
            "test_2024": [],  # 各trialのtest 2024年Sharpe
        },
        "max_drawdown": {
            "test": [],
        },
        "win_rate": {
            "test": [],  # 月次勝率
        },
    },
    "summary": {
        "test_sharpe_mean": None,
        "test_sharpe_std": None,
        "test_sharpe_min": None,
        "test_sharpe_max": None,
        "test_sharpe_positive_ratio": None,  # test Sharpe > 0 の割合
        "test_2023_positive_ratio": None,
        "test_2024_positive_ratio": None,
    },
}
```

---

**作成者**: AI Assistant  
**最終更新**: 2025-12-31  
**次回レビュー推奨**: Holdout検証結果が出た時点
